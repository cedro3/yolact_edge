{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YolactEdge_demo",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedro3/yolact_edge/blob/master/YolactEdge_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPSX2B9oImsQ"
      },
      "source": [
        "# セットアップ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpmc_BiNI98H"
      },
      "source": [
        "# Githubからコードをコピー、重みをダウンロード\n",
        "!git clone https://github.com/cedro3/yolact_edge.git\n",
        "!git clone https://github.com/chentinghao/download_google_drive.git\n",
        "\n",
        "%cd yolact_edge\n",
        "!mkdir -p weights\n",
        "\n",
        "!python ../download_google_drive/download_gdrive.py 1EAzO-vRDZ2hupUJ4JFSUi40lAZ5Jo-Bp ./weights/yolact_edge_54_800000.pth\n",
        "!python ../download_google_drive/download_gdrive.py 15jyd5CRJxNiA41UMjGbaSnmaytfeILfI ./calib_images_coco.zip\n",
        "!unzip -q calib_images_coco.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtE4ZPu0HPD3"
      },
      "source": [
        "# ライブラリー・インポート\n",
        "from eval import *\n",
        "from utils.logging_helper import setup_logger\n",
        "from google.colab.patches import cv2_imshow\n",
        "from video_2_images import video_2_images\n",
        "parse_args([\"--config=yolact_edge_config\", \"--calib_images=../calib_images\"])\n",
        "from eval import args\n",
        "\n",
        "setup_logger(logging_level=logging.INFO)\n",
        "logger = logging.getLogger(\"yolact.eval\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q_45xoMOSyp"
      },
      "source": [
        "# 学習済みモデル構築\n",
        "args.trained_model = \"./weights/yolact_edge_54_800000.pth\"\n",
        "args.yolact_transfer = True\n",
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "logger.info('Loading model...')\n",
        "net = Yolact(training=False)\n",
        "net.load_weights(args.trained_model, args=args)\n",
        "net.eval()\n",
        "logger.info('Model loaded.')\n",
        "\n",
        "net.detect.use_fast_nms = args.fast_nms\n",
        "cfg.mask_proto_debug = args.mask_proto_debug\n",
        "\n",
        "args.score_threshold = 0.15 \n",
        "args.top_k = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm42xX7PhXjQ"
      },
      "source": [
        "# 静止画から物体検出する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1kg3khTI8Uq"
      },
      "source": [
        "# サンプル画像を確認する\n",
        "im = cv2.imread(\"./pic/sample.jpg\")\n",
        "cv2_imshow(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JPuO8FLI1Wu"
      },
      "source": [
        "# 静止画から物体検出\n",
        "frame = torch.from_numpy(im).cuda().float()\n",
        "batch = FastBaseTransform()(frame.unsqueeze(0))\n",
        "\n",
        "extras = {\"backbone\": \"full\", \"interrupt\": False, \"keep_statistics\": False,\n",
        "          \"moving_statistics\": None}\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds = net(batch, extras=extras)[\"pred_outs\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnDuftvBSaA1"
      },
      "source": [
        "# 予測結果を見る\n",
        "dets = preds[0]\n",
        "print('Scores:', dets['score'][:args.top_k])\n",
        "print('Classes:', dets['class'][:args.top_k])\n",
        "print('Boxes:', dets['box'][:args.top_k])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H6_aDmQSXyU"
      },
      "source": [
        "# 物体検出した画像を表示\n",
        "img_numpy = prep_display(preds, frame, None, None, undo_transform=False)\n",
        "cv2_imshow(img_numpy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHKSkgLyhfWu"
      },
      "source": [
        "# ビデオから物体検出する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5EfMsy5i1q7"
      },
      "source": [
        "# mp4動画の再生\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        " \n",
        "mp4 = open('./video/sample.mp4', 'rb').read()\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"80%\" height=\"80%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjKCI0U8YCHf"
      },
      "source": [
        "# 指定したビデオを静止画にバラして images フォルダーに保存する\n",
        "video_2_images('./video/sample.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXKg_PIJDMrk"
      },
      "source": [
        "# 連続して静止画から物体検出\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "files=[]\n",
        "for name in sorted(glob.glob('./images/*.jpg')):\n",
        "     files.append(name)\n",
        "\n",
        "for file in tqdm(files):\n",
        "     img = cv2.imread(file)\n",
        "     frame = torch.from_numpy(img).cuda().float()\n",
        "     batch = FastBaseTransform()(frame.unsqueeze(0))\n",
        "\n",
        "     extras = {\"backbone\": \"full\", \"interrupt\": False, \"keep_statistics\": False,\n",
        "               \"moving_statistics\": None}\n",
        "\n",
        "     with torch.no_grad():\n",
        "          preds = net(batch, extras=extras)[\"pred_outs\"]\n",
        "\n",
        "     img_numpy = prep_display(preds, frame, None, None, undo_transform=False)\n",
        "     cv2.imwrite(file, img_numpy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v1YdBZMM3qz"
      },
      "source": [
        "# 連続した静止画からmp4動画を作成する（既に output.mp4 があれば削除する）\n",
        "if os.path.exists('./output.mp4'):\n",
        "   os.remove('./output.mp4')\n",
        "\n",
        "!ffmpeg -r 30 -i images/%06d.jpg -vcodec libx264 -pix_fmt yuv420p output.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXCLdmpYkQfz"
      },
      "source": [
        "# mp4動画の再生\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        " \n",
        "mp4 = open('./output.mp4', 'rb').read()\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"80%\" height=\"80%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}